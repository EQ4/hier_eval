{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Intro: Music segmentation\n",
      "\n",
      "Let $X \\in \\mathbb{R}^{d\\times t}$ denote a time series of feature data, where $d$ denotes the dimension of features, and $t$ is a time index at some fixed resolution (say, 10Hz).  Existing approaches to music segmentation suppose that there is a single partitioning into $m$ temporally contiguous regions, so that $X=[X_0|X_1|\\cdots|X_m]$.\n",
      "\n",
      "Instead, we will suppose that $X$ can be hierarchically decomposed into a tree structure.  In this view, we have segmentations at multiple resolutions or levels of granularity.  The question now is how to evaluate with or against tree-structured segmentation.\n",
      "\n",
      "## Notation\n",
      "\n",
      "Let $S \\in \\mathcal{P}(X)$ denote a partitioning of the columns of $X$.  We will use the subscripts $S_R$ and $S_E$ to denote *reference* and *estimation*, respectively.  $S(i)$ will denote the identifier of the partition containing item $i$.\n",
      "\n",
      "Hierarchical segmentations will be denoted by $H$ following the subscript conventions above, and the restriction that $H(i)$ denotes the most specific segment containing $i$.  \n",
      "\n",
      "$H(i, j)$ will denote the least common ancestor of $H(i)$ and $H(j)$.  We will denote precedence (containment) of segments by $\\prec$ and $\\preceq$ e.g., $H(i) \\preceq H(i, j)$.  In general, we can interpret $H(\\cdot, \\cdot)$ as a partial order over pairs: not all pairs are comparable, e.g., if $H(a) = H(b)$.  Restricting to a query frame $q$, $H(q, \\cdot)$ induces a partial ranking over the remaining data, in that for all $i, j$.  This will be the key to our evaluation.\n",
      "\n",
      "\n",
      "# Reduction to ranking\n",
      "\n",
      "Observe that flat segmentations are a special case of hierarchical segmentations, where there is one node at the root of the hierarchy containing all frames, and then $m$ segments at the next level down which partition $X$.\n",
      "\n",
      "We can reduce segmentation evaluation to a ranking evaluation problem as follows.  Let $q$ denote any frame/column of $X$, and let $i$ and $j$ denote any two frames such that $S_R(q) = S_R(i)$ and $S_R(q) \\neq S_R(j)$.  In this case, $i$ may be considered *relevant* for $q$, and $j$ is considered *irrelevant* for $q$.  This leads to a straightforward reduction to bipartite ranking, and induces an AUC-style evaluation:\n",
      "\n",
      "$$\n",
      "f(q ; S_E) := \\frac{1}{|S_R(q)|\\cdot (n - |S_R(q)|)} \\sum_{i \\in S_R(q)} \\sum_{j \\notin S_R(q)}  \\mathbb{I}\\left[ S_E(q) = S_E(i) \\neq S_E(j) \\right]\n",
      "$$\n",
      "\n",
      "That is, the score for frame $q$ is the fraction of pairs $(i, j)$ for which $S_E$ agrees with $S_R$ about relevants with respect to $q$ (i.e., membership in the segment).\n",
      "\n",
      "Averaging over all $q$ gives the AUC score\n",
      "\n",
      "$$\n",
      "AUC(S_E) := \\frac{1}{n} \\sum_q f(q ; S_E)\n",
      "$$\n",
      "\n",
      "## Partial ranking\n",
      "\n",
      "Note that $f$ is defined in terms of membership (in)equalities.  In the flat case, we can equivalently reason about strict precedences.  Rather than compare $i$ and $j$ where $S(q) = S(i) \\neq S(j)$, we can express this as $H(q, i) \\prec H(q, j)$.  That is, $q$ and $i$ merge before $q$ and $j$:\n",
      "\n",
      "$$\n",
      "g(q ; H_E) := \\frac{1}{Z_q} \\sum_{i,j : H_R(q, i) \\prec H_R(q, j)}  \\mathbb{I}\\left[ H_E(q, i) \\prec H_E(q, j) \\right]\n",
      "$$\n",
      "where $Z_q$ is a normalization term that counts the number of terms in the summation.\n",
      "\n",
      "$g$ can be viewed as a generalized AUC over the partial ranking induced by the hierarchical segmentation.  Note that the precedence comparisons here are strict, so we never compare two $i$ and $j$ that merge simultaneously with $q$.\n",
      "\n",
      "Aggregating over all frames $q$, we get the following *generalized AUC*:\n",
      "\n",
      "$$\n",
      "GAUC(H_E) := \\frac{1}{n} \\sum_q g(q ; S_E)\n",
      "$$\n",
      "\n",
      "Note, this loss is equivalent to that evaluated by (McFee & Lanckriet, 2011) for subjective artist similarity.  The difference here is that the reference rankings are induced from ordinal data, and not subject to consistency errors.\n",
      "\n",
      "# Extensions\n",
      "\n",
      "The general approach described above can be adapted in various ways to suit different needs.\n",
      "\n",
      "## Transitivity\n",
      "For instance, it may be advantageous to only compare $i$ and $j$ only when $H(q, j)$ is the parent of $H(q, i)$.  This amounts to evaluating the *transitive reduction* of the partial ranking $H(q, \\cdot)$, and the net effect is that redundant comparisons which would be implied via transitivity cannot inflate the score.\n",
      "\n",
      "## Gain\n",
      "Another extension would be to apply a *gain* correction to each level in the hierarchy, so that comparisons spanning greater distances in the tree contribute less to the score.  This would be analogous to the *normalized discounted cumulative gain* metric for information retrieval, which discounts contributions far down the ranking where users are less likely to click.  Typically, in ranking, a cutoff parameter $k$ is introduced so that results at positions beyond $k$ do not contribute to the score.  \n",
      "\n",
      "In segment eval, gain and cutoff parameters would amount to discounting and/or lower-bounding the depth of comparisons.  One may expect that near the root of the hierarchy, there is so little information that it would be meaningless to include comparisons (or give them much weight).\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}